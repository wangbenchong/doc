# 框架流程

## Built-In

以屏幕置灰效果为例，shader写法：

```c
Properties
{
    _MainTex("Texture", 2D) = "white" {}
    _GrayScaleAmount ("GrayScale Amount", Range(0.0,1.0)) = 1.0
}
SubShader
{
    Pass
    {
        CGPROGRAM
        #pragma vertex vert_img
        #pragma fragment frag
        #include "UnityCG.cginc"
        sampler2D _MainTex;
        half _GrayScaleAmount;
        half4 frag(v2f_img i) : SV_Target
        {
            half4 renderTex = tex2D(_MainTex, i.uv);
            float grayScale = 0.299 * renderTex.r + 0.587 * renderTex.g + 0.114 * renderTex.b;
            half4 col = lerp(renderTex, grayScale, _GrayScaleAmount);
            return col;
        }
        ENDCG
    }
}
```

建一个C#脚本，组件挂在主相机上，再把shader拖进去一下即可：

```c#
using System.Collections;
using System.Collections.Generic;
using UnityEngine;

[ExecuteInEditMode]
public class TestRenderImage : MonoBehaviour {
    //把shader拖到这里
    public Shader curShader;
    [Range(0.0f,1.0f)]
    public float grayScaleAmount = 1.0f;
    private Material curMaterial;

    public Material CurMaterial {
        get{
            if (curMaterial == null) {
                Material mat = new Material (curShader);
                mat.hideFlags = HideFlags.HideAndDontSave;
                curMaterial = mat;
            }
            return curMaterial;
        }
    }
    // Use this for initialization
    void Start () {
        if (!SystemInfo.supportsImageEffects) {
            enabled = false;
            return;
        }
        if (!curShader && !curShader.isSupported) {
            enabled = false;
        }
    }

    void OnDisable(){
        if (curMaterial) {
            DestroyImmediate (curMaterial);
        }
    }

    void OnRenderImage(RenderTexture srcTexture, RenderTexture destTexture){
        if (curShader != null) {
            CurMaterial.SetFloat ("_GrayScaleAmount", grayScaleAmount);
            Graphics.Blit (srcTexture, destTexture, CurMaterial);
        } else {
            Graphics.Blit (srcTexture, destTexture);
        }
    }
}

```



## URP12~14

### 搭建框架

仓库借鉴：

- https://github.com/SleeplessOwl0102/URP-Custom-Post-Processing

文章参考：

- [URP系列教程 | 如何使用Scriptable Renderer Feature来自定义后处理效果 - 哔哩哔哩 (bilibili.com)](https://www.bilibili.com/read/cv11343490/)

注意：Unity2021，URP12不得使用RTHandle相关代码（功能不完整，且混乱）Unity2022.3x可以使用，Unity2023不推荐。

创建自定义RenderPassFeature

```mermaid
graph LR
Project窗体内右键--> Create --> Rendering --> URP_Renderer_Feature
```

生成模板代码如下：

```c#
using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;

public class CustomRenderPassFeature : ScriptableRendererFeature
{
    class CustomRenderPass : ScriptableRenderPass
    {
/*方法在执行Pass之前调用
用来配置 render targets 以及 clear state. 还有创建临时render target textures.
不写默认指向active camera.
不要调用CommandBuffer.SetRenderTarget.而应调用 ConfigureTarget和ConfigureClear
渲染管道将确保以高性能的方式进行目标设置和清除*/
        public override void OnCameraSetup(CommandBuffer cmd, ref RenderingData renderingData)
        {
        }
/*在这里可以实现渲染逻辑。
使用ScriptableRenderContext发出绘图命令或执行命令缓冲区
https://docs.unity3d.com/ScriptReference/Rendering.ScriptableRenderContext.html
您不必调用ScriptableRenderContent.submit，渲染管道将在管道中的特定点调用它。*/
        public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData)
        {
            //主要函数，类似于builtin的OnRenderImage
        }

        //清理在执行此渲染过程中创建的所有已分配资源。
        public override void OnCameraCleanup(CommandBuffer cmd)
        {
        }
    }

    CustomRenderPass m_ScriptablePass;

    public override void Create()
    {
        m_ScriptablePass = new CustomRenderPass();

        //配置应该注入渲染过程的位置
        m_ScriptablePass.renderPassEvent = RenderPassEvent.AfterRenderingOpaques;
        //这里后处理一般改用RenderPassEvent.BeforeRenderingPostProcessing
    }
    /*在这里，可以给renderer注入一个或多个pass。
    当为每个摄影机设置一次渲染器时，会调用此方法。*/
    public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData)
    {
        //TODO：CustomRenderPass成员变量执行SetUp
        renderer.EnqueuePass(m_ScriptablePass);
    }
}
```

出于框架化的需求，上面的模板代码要做以下重构和补充：

#### PostProcessRenderFeature.cs

```c#
using UnityEngine.Rendering.Universal;
namespace Custom.URPPostProcessing
{
public class PostProcessRenderFeature : ScriptableRendererFeature
{
    public PostProcessOrderConfig config;

    private PostProcessRenderPass afterSkyboxPass;
    private PostProcessRenderPass beforeNativePostProcessPass;
    private PostProcessRenderPass afterNativePostProcessPass;

    public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData)
    {
        if(afterSkyboxPass != null)
            renderer.EnqueuePass(afterSkyboxPass);

        if(beforeNativePostProcessPass != null)
            renderer.EnqueuePass(beforeNativePostProcessPass);

        if(afterNativePostProcessPass != null)
            renderer.EnqueuePass(afterNativePostProcessPass);
    }

    public override void Create()
    {
#if UNITY_EDITOR
        if (config == null)
            return;
        config.OnDataChange = Create;
#endif

        if (config.afterSkybox.Count > 0)
        {
            afterSkyboxPass = new PostProcessRenderPass(RenderPassEvent.AfterRenderingSkybox, config);
        }

        if (config.beforePostProcess.Count > 0)
        {
            beforeNativePostProcessPass = new PostProcessRenderPass(RenderPassEvent.BeforeRenderingPostProcessing, config);
        }

        if (config.afterPostProcess.Count > 0)
        {
            afterNativePostProcessPass = new PostProcessRenderPass(RenderPassEvent.AfterRenderingPostProcessing, config);
        }
    }
}
}
```

#### PostProcessRenderPass.cs

```c#
using System;
using System.Collections.Generic;
using System.Linq;
using UnityEngine;
using UnityEngine.Assertions;
using UnityEngine.Experimental.Rendering;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;

namespace Custom.URPPostProcessing
{
public class PostProcessRenderPass : ScriptableRenderPass
{
    private string displayName;
    private int cycleRT_1 = Shader.PropertyToID("cycleRT_1");
    private int cycleRT_2 = Shader.PropertyToID("cycleRT_2");
    private List<Type> volumeTypeList;
    private List<PostProcessVolumeComponent> activeVolumeList;
    private GraphicsFormat defaultHDRFormat;

    public PostProcessRenderPass(RenderPassEvent passEvent, PostProcessOrderConfig config)
    {
        displayName = $"CustomPostProcessPass {passEvent}";
        renderPassEvent = passEvent;

        activeVolumeList = new List<PostProcessVolumeComponent>();
        volumeTypeList = new List<Type>();

        var piplineAsset = GraphicsSettings.renderPipelineAsset as UniversalRenderPipelineAsset;
        if (SystemInfo.IsFormatSupported(GraphicsFormat.B10G11R11_UFloatPack32, FormatUsage.Linear | FormatUsage.Render)
            && piplineAsset.supportsHDR)
        {
            defaultHDRFormat = GraphicsFormat.B10G11R11_UFloatPack32;
        }
        else
        {
            defaultHDRFormat = QualitySettings.activeColorSpace == ColorSpace.Linear
                ? GraphicsFormat.R8G8B8A8_SRGB
                : GraphicsFormat.R8G8B8A8_UNorm;
        }

        //collect all custom postprocess volume belong this InjectionPoint
        var allVolumeTypes = VolumeManager.instance.baseComponentTypeArray;
        foreach (var volumeName in config.GetVolumeList((InjectionPoint)renderPassEvent))
        {
            var volumeType = allVolumeTypes.ToList().Find((t) => { return t.ToString() == volumeName; });

            //check volume type is valid
            Assert.IsNotNull(volumeType, $"Can't find Volume : [{volumeName}] , Remove it from config");
            volumeTypeList.Add(volumeType);
        }
    }

    public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData)
    {
        if (volumeTypeList.Count == 0)
            return;

        if (renderingData.cameraData.postProcessEnabled == false)
            return;

        //collect active pp volume
        activeVolumeList.Clear();
        bool isSceneViewCamera = renderingData.cameraData.isSceneViewCamera;
        foreach (var item in volumeTypeList)
        {
            var volumeComp = VolumeManager.instance.stack.GetComponent(item) as PostProcessVolumeComponent;

            if (volumeComp.IsActive() == false)
                continue;
            if (isSceneViewCamera && volumeComp.visibleInSceneView == false)
                continue;

            activeVolumeList.Add(volumeComp);
            volumeComp.SetupIfNeed();
        }

        if (activeVolumeList.Count <= 0)
            return;

        CommandBuffer cb = CommandBufferPool.Get();
        cb.name = displayName;

        var cameraData = renderingData.cameraData;
        var pixelRect = cameraData.camera.pixelRect;
        float scale = cameraData.isSceneViewCamera ? 1 : cameraData.renderScale;
        int width = (int)(pixelRect.width * scale);
        int height = (int)(pixelRect.height * scale);
        cb.GetTemporaryRT(cycleRT_1, width, height, 0, FilterMode.Bilinear, defaultHDRFormat);
        cb.GetTemporaryRT(cycleRT_2, width, height, 0, FilterMode.Bilinear, defaultHDRFormat);
        var target = cycleRT_1;
        var source = cycleRT_2;

        for (int i = 0; i < activeVolumeList.Count; i++)
        {
            var volumeComp = activeVolumeList[i];

            if (i == 0)
            {
                cb.Blit(BuiltinRenderTextureType.CurrentActive, source);
            }
            else
            {
                CoreUtils.Swap(ref target, ref source);
            }

            RenderTargetIdentifier renderTarget;
            bool isFinalVolume = i == activeVolumeList.Count - 1;
            if (isFinalVolume)
            {
                bool renderToDefaultColorTexture =
                    renderPassEvent == RenderPassEvent.BeforeRenderingPostProcessing
                    || renderPassEvent == RenderPassEvent.AfterRenderingSkybox;

                if (renderToDefaultColorTexture)
                {
                    //可通过相同方式按引用访问值。 在某些情况下，按引用访问值可避免潜在的高开销复制操作，从而提高性能。 例如，以下语句显示如何定义一个用于引用值的 ref 局部变量。
                    ref ScriptableRenderer renderer = ref cameraData.renderer;
                    renderTarget = renderer.cameraColorTarget;//.cameraColorTargetHandle;
                }
                else
                {
                    renderTarget = BuiltinRenderTextureType.CameraTarget;
                }
            }
            else
            {
                renderTarget = target;
            }
            cb.SetRenderTarget(renderTarget);

            cb.BeginSample(volumeComp.displayName);
            volumeComp.Render(cb, renderingData.cameraData.camera, source, renderTarget);
            cb.EndSample(volumeComp.displayName);
        }

        cb.ReleaseTemporaryRT(source);
        cb.ReleaseTemporaryRT(target);
        context.ExecuteCommandBuffer(cb);
        cb.Clear();
        CommandBufferPool.Release(cb);
    }
}
}
```

#### PostProcessOrderConfig.cs

```c#
using System;
using System.Collections.Generic;
using UnityEngine;

namespace Custom.URPPostProcessing
{
[CreateAssetMenu(menuName = "Custom/PostProcess Order Config")]
public class PostProcessOrderConfig : ScriptableObject
{
    public List<string> afterSkybox = new List<string>();
    public List<string> beforePostProcess = new List<string>();
    public List<string> afterPostProcess = new List<string>();

    public List<string> GetVolumeList(InjectionPoint point)
    {
        switch (point)
        {
            case InjectionPoint.AfterOpaqueAndSky:
                return afterSkybox;
            case InjectionPoint.BeforePostProcess:
                return beforePostProcess;
            case InjectionPoint.AfterPostProcess:
                return afterPostProcess;
        }
        return null;
    }
#if UNITY_EDITOR
    public Action OnDataChange;

    private void OnValidate()
    {
        OnDataChange?.Invoke();
    }
#endif
}
}
```

#### PostProcessOrderConfigEditor.cs

```c#
#if UNITY_EDITOR
using UnityEditor;
using UnityEditorInternal;
using UnityEngine.Rendering;
using static UnityEditor.GenericMenu;
using static UnityEditorInternal.ReorderableList;

namespace Custom.URPPostProcessing.CEditor
{
[CustomEditor(typeof(PostProcessOrderConfig))]
[CanEditMultipleObjects]
public class PostProcessOrderConfigEditor : Editor
{
    private ReorderableList beforePost;
    private ReorderableList afterPost;
    private ReorderableList afterSkybox;

    private PostProcessOrderConfig instance;

    public override void OnInspectorGUI()
    {
        //base.DrawDefaultInspector();
        serializedObject.Update();
        {
            afterSkybox.DoLayoutList();
            EditorGUILayout.Space();
            beforePost.DoLayoutList();
            EditorGUILayout.Space();
            afterPost.DoLayoutList();
        }
        serializedObject.ApplyModifiedProperties();
    }

    private void OnEnable()
    {
        instance = (PostProcessOrderConfig)target;

        var afterSkyboxProp = serializedObject.FindProperty("afterSkybox");
        afterSkybox = CreateAutoLayout(afterSkyboxProp, "After Skybox");
        afterSkybox.drawElementCallback = DrawElement(afterSkybox);
        afterSkybox.onAddDropdownCallback = DrawDropdownMenu(InjectionPoint.AfterOpaqueAndSky);

        var beforePostProp = serializedObject.FindProperty("beforePostProcess");
        beforePost = CreateAutoLayout(beforePostProp, "Before Post-Process");
        beforePost.drawElementCallback = DrawElement(beforePost);
        beforePost.onAddDropdownCallback = DrawDropdownMenu(InjectionPoint.BeforePostProcess);

        var afterPostProp = serializedObject.FindProperty("afterPostProcess");
        afterPost = CreateAutoLayout(afterPostProp, "After Post-Process");
        afterPost.drawElementCallback = DrawElement(afterPost);
        afterPost.onAddDropdownCallback = DrawDropdownMenu(InjectionPoint.AfterPostProcess);
    }

    private AddDropdownCallbackDelegate DrawDropdownMenu(InjectionPoint injectionPoint)
    {
        return (buttonRect, list) =>
        {
            var menu = new GenericMenu();

            foreach (var item in VolumeManager.instance.baseComponentTypeArray)
            {
                var comp = VolumeManager.instance.stack.GetComponent(item) as PostProcessVolumeComponent;

                if (comp == null)
                    continue;

                if (comp.InjectionPoint != injectionPoint)
                    continue;

                menu.AddItem(new GUIContent(comp.GetType().ToString()), false, tryAddVolumeComp(comp, injectionPoint));
            }

            menu.ShowAsContext();
        };

        MenuFunction tryAddVolumeComp(object userData, InjectionPoint customInjectionPoint)
        {
            return () =>
            {
                var data = userData as PostProcessVolumeComponent;
                var typeName = data.GetType().ToString();
                var list = instance.GetVolumeList(customInjectionPoint);
                if (list.Contains(typeName) == false)
                {
                    list.Add(typeName);
                    instance.OnDataChange?.Invoke();
                    EditorUtility.SetDirty(instance);
                }
            };
        }
    }

    private ElementCallbackDelegate DrawElement(ReorderableList list)
    {
        return (rect, index, isActive, isFocused) =>
        {
            var prop = list.serializedProperty;
            var item = prop.GetArrayElementAtIndex(index);
            rect.height = EditorGUI.GetPropertyHeight(item);
            EditorGUI.LabelField(rect, item.stringValue);
        };
    }
    public ReorderableList CreateAutoLayout(SerializedProperty property, string headers)
    {
        var list = new ReorderableList(property.serializedObject, property, true, true, true, true);

        list.drawElementCallback = DrawDefaultElement(list);
        list.drawHeaderCallback = DrawHeader(headers);

        return list;
    }

    private ElementCallbackDelegate DrawDefaultElement(ReorderableList list)
    {
        return (rect, index, isActive, isFocused) =>
        {
            var property = list.serializedProperty;
            for (var i = 0; i < property.arraySize; i++)
            {
                rect.height = EditorGUI.GetPropertyHeight(property.GetArrayElementAtIndex(index));
                EditorGUI.PropertyField(rect, property.GetArrayElementAtIndex(index), GUIContent.none);
            }
        };
    }

    private HeaderCallbackDelegate DrawHeader(string header)
    {
        return (rect) =>
        {
            EditorGUI.LabelField(rect, header, EditorStyles.boldLabel);
        };
    }
}
}
#endif
```



#### Util_PP.cs

```c#
using UnityEngine;
using UnityEngine.Rendering;

namespace Custom.URPPostProcessing
{
    public static class Util_PP
    {
        public static readonly int PostBufferID = Shader.PropertyToID("_PostSource");

        public static void SetPostProcessSourceTexture(this CommandBuffer cb, RenderTargetIdentifier identifier)
        {
            cb.SetGlobalTexture(PostBufferID, identifier);
        }

        public static void DrawFullScreenTriangle(this CommandBuffer cb, Material material, RenderTargetIdentifier destination, int shaderPass = 0)
        {
            CoreUtils.SetRenderTarget(cb, destination);
            cb.DrawProcedural(Matrix4x4.identity, material, shaderPass, MeshTopology.Triangles, 3, 1, null);
        }

        public static void SetKeyWord(this Material mat, string keyWord, bool active)
        {
            if (active)
                mat.EnableKeyword(keyWord);
            else
                mat.DisableKeyword(keyWord);
        }
    }
}
```

#### PostProcessVolumeComponent.cs

```c#
using UnityEngine;
using UnityEngine.Rendering;

namespace Custom.URPPostProcessing
{
    public enum InjectionPoint
    {
        AfterOpaqueAndSky = 400,
        BeforePostProcess = 550,
        AfterPostProcess = 600,
    }

    public abstract class PostProcessVolumeComponent : VolumeComponent
    {
        protected PostProcessVolumeComponent()
        {
            string className = GetType().ToString();
            int dotIndex = className.LastIndexOf(".") + 1;
            displayName = className.Substring(dotIndex);
        }

        public virtual InjectionPoint InjectionPoint { get; } = InjectionPoint.BeforePostProcess;

        public virtual bool visibleInSceneView { get; } = true;

        public abstract bool IsActive();

        public abstract void Initialize();

        public abstract void Render(CommandBuffer cb, Camera camera, RenderTargetIdentifier source, RenderTargetIdentifier dest);

        internal bool isInitialized = false;

        internal void SetupIfNeed()
        {
            if (isInitialized == true)
                return;

            Initialize();
            isInitialized = true;
        }

        protected override void OnDestroy()
        {
            base.OnDestroy();
            isInitialized = false;
            CleanUp();
        }

        protected virtual void CleanUp()
        {

        }
    }
}
```

#### 前期准备工作

- 主相机的Rendering-PostProcess（打钩）

- 生成配置assets文件PostProcessOrderConfig.asset

```mermaid
graph LR
Assets--> Create --> S[Custom] --> POC[PostProcess Order Config]
```

- 如果没有就生成Volume配置文件NewVolumeProfile.asset，已备场景中Volume组件使用

  ```mermaid
  graph LR
  Assets--> Create --> VP[Volume Profile]
  ```

  

### 实际应用

有了这套框架，添加后处理效果只需要创建一个继承自PostProcessVolumeComponent的Volume子类，和一个对应的shader脚本（放在Resources目录下）。

具体工作流及示例代码如下（以HalfTone效果为例）：

1. 自行创建C#脚本HalfToneVolume.cs如下：

```c#
using System;
using UnityEngine;
using UnityEngine.Rendering;
namespace Custom.URPPostProcessing
{
    [Serializable, VolumeComponentMenu("Custom PostProcessing/HalfTone")]
    public sealed class HalfToneVolume : PostProcessVolumeComponent
    {
        public BoolParameter _visibleInSceneview = new BoolParameter(true);
        public FloatParameter _Density = new FloatParameter(0);
        public FloatParameter _Radius = new FloatParameter(0.3f);
        public FloatParameter _SmoothEdge = new FloatParameter(0.2f);
        public FloatParameter _HalfToneFactor = new FloatParameter(0.5f);
        public FloatParameter _SourceFactor = new FloatParameter(0.5f);
        public FloatParameter _Lightness = new FloatParameter(1);
        public ColorParameter _PointColor = new ColorParameter(new Color(0, 0, 0, 1));
        public ColorParameter _ColorFactor = new ColorParameter(new Color(1, 1, 1, 1));

        private Material material;

        //Define this Post-Processing will be executed in which timing in URP pipeline.
        public override InjectionPoint InjectionPoint => InjectionPoint.BeforePostProcess;

        //Default is true.
        public override bool visibleInSceneView => _visibleInSceneview.value;

        //If return false, will skip this Post-Processing.
        //You should ensure the default parameter value will return false in this method, let disable volume component work.
        public override bool IsActive() => _Density.value != 0;

        //Cache parameter ids to avoid do the same thing every update.
        static class IDs
        {
            internal readonly static int _Density = Shader.PropertyToID("_Density");
            internal readonly static int _Radius = Shader.PropertyToID("_Radius");
            internal readonly static int _SmoothEdge = Shader.PropertyToID("_SmoothEdge");
            internal readonly static int _HalfToneFactor = Shader.PropertyToID("_HalfToneFactor");
            internal readonly static int _SourceFactor = Shader.PropertyToID("_SourceFactor");
            internal readonly static int _Lightness = Shader.PropertyToID("_Lightness");
            internal readonly static int _Color01 = Shader.PropertyToID("_Color01");
            internal readonly static int _ColorFactor = Shader.PropertyToID("_ColorFactor");
        }

        //Create shader material.
        //You should put shader in the Resources folder, ensure it will be included in Asset Bundle, or add it use another way by yourself.
        public override void Initialize()
        {
            material = CoreUtils.CreateEngineMaterial("Custom/Post-Processing/HalfTone");
        }

        public override void Render(CommandBuffer cb, Camera camera, RenderTargetIdentifier source, RenderTargetIdentifier destination)
        {
            //Update parameter
            material.SetFloat(IDs._Density, _Density.value);
            material.SetFloat(IDs._Radius, _Radius.value);
            material.SetFloat(IDs._SmoothEdge, _SmoothEdge.value);
            material.SetFloat(IDs._HalfToneFactor, _HalfToneFactor.value);
            material.SetFloat(IDs._SourceFactor, _SourceFactor.value);
            material.SetFloat(IDs._Lightness, _Lightness.value);
            material.SetColor(IDs._Color01, _PointColor.value);
            material.SetColor(IDs._ColorFactor, _ColorFactor.value);

            //Set RenderTexture for shader use.
            cb.SetPostProcessSourceTexture(source);

            //Set render target and draw.
            cb.DrawFullScreenTriangle(material, destination);
        }

        //Do something before Destroy(), if you need.
        protected override void CleanUp()
        {

        }
    }
}
```

2. 在Resources目录下创建对应的Shader：

```c
Shader "Custom/Post-Processing/HalfTone"
{
	SubShader
	{
		Cull Off
		ZWrite Off
		ZTest Off

		Pass
		{
			HLSLPROGRAM
			#pragma vertex vert
			#pragma fragment frag

			#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
			#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

			struct appdata
			{
				uint vertexID : SV_VertexID;
			};

			struct v2f
			{
				float4 uv : TEXCOORD0;
				float4 vertex : SV_POSITION;

			};

			float _Density;
			float _Radius;
			float _SmoothEdge;
			float _HalfToneFactor;
			float _SourceFactor;
			float _Lightness;
			float4 _Color01;
			float4 _ColorFactor;

			TEXTURE2D_X(_PostSource);
			SAMPLER(sampler_PostSource);

			v2f vert(appdata v)
			{
				v2f o;

				o.vertex = GetFullScreenTriangleVertexPosition(v.vertexID);
				o.uv.xy = GetFullScreenTriangleTexCoord(v.vertexID);

				float aspect = _ScreenParams.x / _ScreenParams.y;
				float2 uu;
				uu.x = o.uv.x * aspect;
				uu.y = o.uv.y;
				float angle = sin(radians(45));
				o.uv.zw = mul(float2x2(angle, -angle, angle, angle), uu);
				return o;
			}

			sampler2D _halfToneFlag;

			float4 frag(v2f i) : SV_Target
			{

				float3 texColor = SAMPLE_TEXTURE2D_X(_PostSource, sampler_PostSource, i.uv.xy).rgb;

				float lightness = (texColor.r * _ColorFactor.r + texColor.g * _ColorFactor.g + texColor.b * _ColorFactor.b) * _Lightness;
				float radius = 1 - lightness + _Radius;

				/*
				//如果項目是2D Platform類遊戲，並且有一個主要focus的深度，可以使用距離對UV做位移，讓在主要深度上的點點看起來是固定不動的。
				//以下為 FOV 60  深度 8 的例子
				//9.2376043070 = tan(30(half camera fov) * 8(z depth) * 2)
				//compute shift let post effect point no move on Z-axis equal 0
				
				i.uv.zw = frac(i.uv.zw + _WorldSpaceCameraPos.x / 9.2376043070 * sin(radians(45)));
				i.uv.z = frac(i.uv.z - _WorldSpaceCameraPos.y / 9.2376043070 * sin(radians(45)));
				i.uv.w = frac(i.uv.w + _WorldSpaceCameraPos.y / 9.2376043070 * sin(radians(45)));
				*/

				float2 vectorCenter = 2 * frac(_Density * i.uv.zw) - 1;
				float distance = length(vectorCenter);

				float circle = 1 - smoothstep(radius, radius + _SmoothEdge, distance);
				float3 halftoneColor = lerp(float4(1,1,1,1), _Color01, circle).rgb;

				halftoneColor = texColor * halftoneColor * _HalfToneFactor;

				float3 color = texColor * _SourceFactor + halftoneColor;
				return float4(color, 1);
			}
			ENDHLSL
		}
	}
}
```

3. 选中一个Volume Profile文件，点“Add Overide”按钮，追加刚刚创建的效果。
4. 场景中创建Volume物体，把Volume Profile赋进去，就能看到效果了。

## URP17

[Unity6完整可编程RenderFeature示例](./不同Unity版本实现可编程RenderFeature/Unity6完整可编程RenderFeature示例.md)

# 效果与原理

## Tonemapping

相关术语名词：HDR，SDR，LDR（后两者一个意思），Tonemapping就是的HDR转SDR的一套算法，目前最优解为ACES ToneMapping（早期还有Reinhard ToneMapping、CE ToneMapping、Filmic ToneMapping）参考文章：[Tone Mapping（色调映射](https://moontree.github.io/2020/08/30/tone-mapping/)

## 径向模糊

```c
half4 radialfrag(v2f i) : SV_Target
{
    float4 col = 0;
    float2 dir = (float2(_X,_Y) - i.uv) * _BlurRange * 0.01;
    float blurParams = saturate(distance(i.uv,float2(_X,_Y)) / _BufferRadius);  // 控制不模糊的半径
    for(int t = 0; t < _BlurTimes; t++)
    {
        col += SAMPLE_TEXTURE2D(_PostSource, sampler_PostSource, i.uv + dir * t * blurParams)/ _BlurTimes;
    }
    return col;
}
```



## 十种模糊

- 高斯模糊（Gaussian Blur）

- 方框模糊（Box Blur）

- Kawase模糊（Kawase Blur）

- 双重模糊（Dual Blur）

- 散景模糊（Bokeh Blur）

- 移轴模糊（Tilt Shift Blur）

- 光圈模糊（Iris Blur）

- 粒状模糊（Grainy Blur）

- 径向模糊（Radial Blur）

- 方向模糊（Directional Blur）

参考文章：[高品质后处理：十种图像模糊算法的总结与实现_鉴别图像模糊的算法-CSDN博客](https://blog.csdn.net/poem_qianmo/article/details/105350519)

其中综合效果最好的是：双重模糊 Dual Blur，[参考github](https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/DualKawaseBlur)

为了带来更好的性能表现，可以将uv的偏移放在Vert Shader中进行，而Fragment Shader中基本上仅进行采样即可。

DualKawaseBlur.shader主要代码：

```c
HLSLINCLUDE

uniform float4 _MainTex_ST;
uniform half _Offset;

struct v2f_DownSample
{
    float4 vertex: SV_POSITION;
    float2 texcoord: TEXCOORD0;
    float2 uv: TEXCOORD1;
    float4 uv01: TEXCOORD2;
    float4 uv23: TEXCOORD3;
};


struct v2f_UpSample
{
    float4 vertex: SV_POSITION;
    float2 texcoord: TEXCOORD0;
    float4 uv01: TEXCOORD1;
    float4 uv23: TEXCOORD2;
    float4 uv45: TEXCOORD3;
    float4 uv67: TEXCOORD4;
};

//用两个pass依次分别做这两个vert，urp不会自动做两个pass，要C#去调用
v2f_DownSample Vert_DownSample(AttributesDefault v)
{
    v2f_DownSample o;
    o.vertex = float4(v.vertex.xy, 0.0, 1.0);
    o.texcoord = TransformTriangleVertexToUV(v.vertex.xy);


    #if UNITY_UV_STARTS_AT_TOP
        o.texcoord = o.texcoord * float2(1.0, -1.0) + float2(0.0, 1.0);
    #endif
    float2 uv = TRANSFORM_TEX(o.texcoord, _MainTex);

    _MainTex_TexelSize *= 0.5;
    o.uv = uv;
    o.uv01.xy = uv - _MainTex_TexelSize * float2(1 + _Offset, 1 + _Offset);//top right
    o.uv01.zw = uv + _MainTex_TexelSize * float2(1 + _Offset, 1 + _Offset);//bottom left
    o.uv23.xy = uv - float2(_MainTex_TexelSize.x, -_MainTex_TexelSize.y) * float2(1 + _Offset, 1 + _Offset);//top left
    o.uv23.zw = uv + float2(_MainTex_TexelSize.x, -_MainTex_TexelSize.y) * float2(1 + _Offset, 1 + _Offset);//bottom right

    return o;
}
v2f_UpSample Vert_UpSample(AttributesDefault v)
{
    v2f_UpSample o;
    o.vertex = float4(v.vertex.xy, 0.0, 1.0);
    o.texcoord = TransformTriangleVertexToUV(v.vertex.xy);

    #if UNITY_UV_STARTS_AT_TOP
        o.texcoord = o.texcoord * float2(1.0, -1.0) + float2(0.0, 1.0);
    #endif
    float2 uv = TRANSFORM_TEX(o.texcoord, _MainTex);

    _MainTex_TexelSize *= 0.5;
    _Offset = float2(1 + _Offset, 1 + _Offset);

    o.uv01.xy = uv + float2(-_MainTex_TexelSize.x * 2, 0) * _Offset;
    o.uv01.zw = uv + float2(-_MainTex_TexelSize.x, _MainTex_TexelSize.y) * _Offset;
    o.uv23.xy = uv + float2(0, _MainTex_TexelSize.y * 2) * _Offset;
    o.uv23.zw = uv + _MainTex_TexelSize * _Offset;
    o.uv45.xy = uv + float2(_MainTex_TexelSize.x * 2, 0) * _Offset;
    o.uv45.zw = uv + float2(_MainTex_TexelSize.x, -_MainTex_TexelSize.y) * _Offset;
    o.uv67.xy = uv + float2(0, -_MainTex_TexelSize.y * 2) * _Offset;
    o.uv67.zw = uv - _MainTex_TexelSize * _Offset;

    return o;
}
//用两个pass依次分别做这两个frag，urp不会自动做两个pass，要C#去调用
half4 Frag_DownSample(v2f_DownSample i): SV_Target
{
    half4 sum = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv) * 4;
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv01.xy);
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv01.zw);
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv23.xy);
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv23.zw);

    return sum * 0.125;
}
half4 Frag_UpSample(v2f_UpSample i): SV_Target
{
    half4 sum = 0;
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv01.xy);
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv01.zw) * 2;
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv23.xy);
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv23.zw) * 2;
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv45.xy);
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv45.zw) * 2;
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv67.xy);
    sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv67.zw) * 2;

    return sum * 0.0833;
}

ENDHLSL

SubShader
{
    Cull Off ZWrite Off ZTest Always
    Pass
    {
        HLSLPROGRAM
        #pragma vertex Vert_DownSample
        #pragma fragment Frag_DownSample
        ENDHLSL
    }

    Pass
    {
        HLSLPROGRAM
        #pragma vertex Vert_UpSample
        #pragma fragment Frag_UpSample
        ENDHLSL
    }
}
```

## 十种故障效果

- RGB颜色分离故障（RGB Split Glitch）
- 错位图块故障（Image Block Glitch）
  - **Glitch Image Block V1**：<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchImageBlock>

  - **Glitch Image Block V2**：<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchImageBlockV2>

  - **Glitch Image Block V3**：<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchImageBlockV3>

  - **Glitch Image Block V4**：<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchImageBlockV4>

- 错位线条故障（Line Block）

- 图块抖动故障（Tile Jitter Glitch）

- 扫描线抖动故障（Scan Line Jitter Glitch）

- 数字条纹故障（Digital Stripe Glitch）

- 模拟噪点故障（Analog Noise Glitch）

- 屏幕跳跃故障（Screen Jump Glitch）

- 屏幕抖动故障（Screen Shake Glitch）

- 波动抖动故障（Wave Jitter Glitch）

  

  算法核心在于四点：

  -   **噪声函数的选择**：噪声函数是生成各式的干扰信号的源头。

  -   **uv抖动方式的选择**：将噪声函数作用于屏幕空间uv后，基于新的uv进行采样，以产生故障的抖动表现。

  -   **采样通道的选择**：对RGB分别采样，或者选取特定通道进行采样，以实现多种风格的故障表现。

  -   **颜色空间的转换**：善用YUV、CMY、HSV、YIQ、YCbCr
      、YC1C2等空间与RGB空间之间的转换，以实现多种风格的故障表现。

  熟知上述四种故障艺术的算法要点，加上一点创意，配合周边算法，则可以创造出更多富有表现力的故障艺术特效。

## 置灰与留色

```c
half4 radialfrag(v2f i) : SV_Target
{
    half4 col = SAMPLE_TEXTURE2D(_PostSource, sampler_PostSource, i.uv);
    #if KEEP_COLOR
    //这里的_KeepColorMin、_KeepColorMax传过来之前一定要是hdr的
    bool inRangeR = col.r >= _KeepColorMin.r && col.r <= _KeepColorMax.r;  
    bool inRangeG = col.g >= _KeepColorMin.g && col.g <= _KeepColorMax.g;  
    bool inRangeB = col.b >= _KeepColorMin.b && col.b <= _KeepColorMax.b; 
    if(inRangeR && inRangeG && inRangeB)
    {
        return col;
    }
    #endif
    float luminosity = 0.299 * col.r + 0.587 * col.g + 0.114 * col.b;
    half4 finalColor = lerp(col, luminosity, _GrayScale);
    return finalColor;
}
```

